9.0 强化学习的基本概念：

状态，行动，策略，奖励，状态转移（随机性），随机性的两个来源，智能体与环境交互的形式，奖励与回报，价值函数（状态价值函数，行动价值函数）

9.1 强化学习与监督学习的对比

+ 监督学习：输入样本x，满足iid，根据样本x预测输出y，观测输出yi与损失，然后更新w

+ 强化学习：输入根据环境决定的行动x，环境输出下一状态，观测状态与奖励，更新策略

9.2 马尔科夫过程描述：<X, A, P, ,R>

9.3 k摇臂赌博机

10.0 半监督问题

半监督学习的假设：聚类假设（同一类中的样本点很可能有相似的标签）、流形假设（高维的数据有低维的特性）、平滑假设（相似的样本有相同的标记）

10.1 生成式方法

10.2 self-Training

有标签样本上训练一个SVM，在无标签样本上给出伪标签，将一部分无标签样本加入有标签样本集，继续训练（权重）

不能用于回归：软分类—使用熵正则化（选用熵较小的无标签样本or LOSS= CE(y,y^)+\lamda E(y)

10.3 半监督SVM

超平面：将两类有标记样本分隔开，且穿过数据低密度区域

TSVM 的思想–>迭代策略: 

10.4图半监督学习

假设：相似的样本有相同的标签

能量函数E ，求解的两个方法

10.5 基于分歧的方法

多视图数据的相容性–>互补性

协同训练：充分且条件独立的视图

+ 基于标记样本训练学习器1，并给出最自信的未标记样本的假标记，计入视图2 中
+ 在视图2 中训练学习器2，同理

缓冲池？？

10.6 半监督聚类

获得的监督信息：

+ 勿连（不同簇）与必联（相同簇）
+ 未标记样本

约束k-均值：对于每一个点，找最近的簇中心后，先判断加入该簇后是否满足CM条件，若不满足，考虑次近的簇

少量有标记样本的聚类：

+  初始时类中心以有标记样本 各类 均值向量
+ 每次迭代，有标记样本直接分类，无标记样本再划分

